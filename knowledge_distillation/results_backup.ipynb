{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "results_backup.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MZw8zU0YQSwC"
      },
      "outputs": [],
      "source": [
        "#bsic studnet\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(labels,predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BWAfbjJSsWk1",
        "outputId": "0803a9e9-e1f0-4cf7-dfb4-8789ccf1dbf7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         1.0       1.00      0.00      0.01      1351\n",
            "         2.0       0.49      0.99      0.66        98\n",
            "         3.0       0.42      0.94      0.58      1121\n",
            "         4.0       0.00      0.00      0.00       128\n",
            "\n",
            "    accuracy                           0.43      2698\n",
            "   macro avg       0.48      0.48      0.31      2698\n",
            "weighted avg       0.69      0.43      0.27      2698\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#pruned"
      ],
      "metadata": {
        "id": "tKirmpfgQYO3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "student_model.save(\"/content/drive/MyDrive/DL/KD/base_cnn_student.h5\")\n",
        "pruned_keras_file = \"/content/drive/MyDrive/DL/KD/base_cnn_student_strip.h5\"\n",
        "pruned_tflite_file = \"/content/drive/MyDrive/DL/KD/base_cnn_student_strip_tflite.h5\"\n",
        "import tempfile\n",
        "\n",
        "\n",
        "import tensorflow_model_optimization as tfmot\n",
        "\n",
        "prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n",
        "\n",
        "# Compute end step to finish pruning after 2 epochs.\n",
        "batch_size = 32\n",
        "epochs = 2\n",
        "validation_split = 0.1 # 10% of training set will be used for validation set. \n",
        "\n",
        "end_step = 300*epochs\n",
        "# Define model for pruning.\n",
        "pruning_params = {\n",
        "      'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=0.50,\n",
        "                                                               final_sparsity=0.80,\n",
        "                                                               begin_step=0,\n",
        "                                                               end_step=end_step)\n",
        "}\n",
        "\n",
        "model_for_pruning = prune_low_magnitude(student_model, **pruning_params)\n",
        "\n",
        "# `prune_low_magnitude` requires a recompile.\n",
        "model_for_pruning.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "\n",
        "logdir = tempfile.mkdtemp()\n",
        "\n",
        "callbacks = [\n",
        "  tfmot.sparsity.keras.UpdatePruningStep(),\n",
        "  tfmot.sparsity.keras.PruningSummaries(log_dir=logdir),\n",
        "]\n",
        "\n",
        "model_for_pruning.fit(train_ds, epochs=epochs, callbacks=callbacks, validation_data=val_ds,\n",
        ")\n",
        "\n",
        "predictions = np.array([])\n",
        "labels =  np.array([])\n",
        "\n",
        "for x, y in test_ds:\n",
        "  predictions = np.concatenate([predictions, model_for_pruning.predict(x).argmax(axis =1)+1])\n",
        "  labels = np.concatenate([labels, y.numpy()])\n",
        "\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(labels,predictions))\n",
        "\n",
        "\n",
        "model_for_export = tfmot.sparsity.keras.strip_pruning(model_for_pruning)\n",
        "\n",
        "# _, pruned_keras_file = tempfile.mkstemp('.h5')\n",
        "tf.keras.models.save_model(model_for_export, pruned_keras_file, include_optimizer=False)\n",
        "print('Saved pruned Keras model to:', pruned_keras_file)\n",
        "\n",
        "\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model_for_export)\n",
        "pruned_tflite_model = converter.convert()\n",
        "\n",
        "# _, pruned_tflite_file = tempfile.mkstemp('.tflite')\n",
        "\n",
        "with open(pruned_tflite_file, 'wb') as f:\n",
        "  f.write(pruned_tflite_model)\n",
        "\n",
        "print('Saved pruned TFLite model to:', pruned_tflite_file)\n",
        "\n",
        "def get_gzipped_model_size(file):\n",
        "  # Returns size of gzipped model, in bytes.\n",
        "  import os\n",
        "  import zipfile\n",
        "\n",
        "  _, zipped_file = tempfile.mkstemp('.zip')\n",
        "  with zipfile.ZipFile(zipped_file, 'w', compression=zipfile.ZIP_DEFLATED) as f:\n",
        "    f.write(file)\n",
        "\n",
        "  return os.path.getsize(zipped_file)\n",
        "print(\"Size of gzipped baseline Keras model: %.2f bytes\" % (get_gzipped_model_size(keras_file)))\n",
        "print(\"Size of gzipped pruned Keras model: %.2f bytes\" % (get_gzipped_model_size(pruned_keras_file)))\n",
        "print(\"Size of gzipped pruned TFlite model: %.2f bytes\" % (get_gzipped_model_size(pruned_tflite_file)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1sl9cYLbX2Kr",
        "outputId": "c44edc70-6e1d-4455-bc17-e394523bfa42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow_model_optimization/python/core/sparsity/keras/pruning_wrapper.py:218: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
            "  aggregation=tf.VariableAggregation.MEAN)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow_model_optimization/python/core/sparsity/keras/pruning_wrapper.py:225: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
            "  aggregation=tf.VariableAggregation.MEAN)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow_model_optimization/python/core/sparsity/keras/pruning_wrapper.py:238: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
            "  trainable=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "304/304 [==============================] - 406s 1s/step - loss: 0.2424 - accuracy: 0.9289 - val_loss: 3.6064 - val_accuracy: 0.2006\n",
            "Epoch 2/2\n",
            "304/304 [==============================] - 382s 1s/step - loss: 0.2253 - accuracy: 0.9321 - val_loss: 0.3947 - val_accuracy: 0.9565\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         1.0       0.99      0.97      0.98      1351\n",
            "         2.0       0.73      0.99      0.84        98\n",
            "         3.0       1.00      0.96      0.98      1121\n",
            "         4.0       0.73      0.94      0.82       128\n",
            "\n",
            "    accuracy                           0.96      2698\n",
            "   macro avg       0.86      0.96      0.91      2698\n",
            "weighted avg       0.97      0.96      0.97      2698\n",
            "\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Saved pruned Keras model to: /content/drive/MyDrive/DL/KD/base_cnn_student_strip.h5\n",
            "INFO:tensorflow:Assets written to: /tmp/tmpdd0h164z/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved pruned TFLite model to: /content/drive/MyDrive/DL/KD/base_cnn_student_strip_tflite.h5\n",
            "Size of gzipped baseline Keras model: 1457575.00 bytes\n",
            "Size of gzipped pruned Keras model: 468626.00 bytes\n",
            "Size of gzipped pruned TFlite model: 454350.00 bytes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "t4m0CM09VPVE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "distiller = Distiller(student=student_model, teacher=teacher_model)\n",
        "distiller.compile(\n",
        "    optimizer=keras.optimizers.Adam(),\n",
        "    metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
        "    student_loss_fn=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    distillation_loss_fn=keras.losses.KLDivergence(),\n",
        "    alpha=0.1,\n",
        "    temperature=5,\n",
        ")\n",
        "\n",
        "# Distill teacher to student\n",
        "distiller.fit(train_ds, epochs=7)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0bL4N1s9zMTD",
        "outputId": "4e428397-f6ba-4477-be46-bfb89ef359d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "304/304 [==============================] - 322s 1s/step - sparse_categorical_accuracy: 0.7975 - student_loss: 0.6466 - distillation_loss: 0.0017\n",
            "Epoch 2/7\n",
            "304/304 [==============================] - 333s 1s/step - sparse_categorical_accuracy: 0.8680 - student_loss: 0.4348 - distillation_loss: 0.0011\n",
            "Epoch 3/7\n",
            "304/304 [==============================] - 328s 1s/step - sparse_categorical_accuracy: 0.8958 - student_loss: 0.3064 - distillation_loss: 7.7563e-04\n",
            "Epoch 4/7\n",
            "304/304 [==============================] - 328s 1s/step - sparse_categorical_accuracy: 0.9145 - student_loss: 0.2632 - distillation_loss: 6.5174e-04\n",
            "Epoch 5/7\n",
            "304/304 [==============================] - 326s 1s/step - sparse_categorical_accuracy: 0.9387 - student_loss: 0.1991 - distillation_loss: 4.9662e-04\n",
            "Epoch 6/7\n",
            "304/304 [==============================] - 320s 1s/step - sparse_categorical_accuracy: 0.9514 - student_loss: 0.1600 - distillation_loss: 3.9634e-04\n",
            "Epoch 7/7\n",
            "304/304 [==============================] - 320s 1s/step - sparse_categorical_accuracy: 0.9634 - student_loss: 0.1297 - distillation_loss: 3.1307e-04\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f51ec19ea90>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##################################################################################"
      ],
      "metadata": {
        "id": "JQkZidymU4-T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 128 student\n"
      ],
      "metadata": {
        "id": "NxIr74b7jT2t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(labels,predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52d2cca7-18db-42d9-f564-115b3449c8ae",
        "id": "BWZLj7iPjWqb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         1.0       0.99      0.99      0.99      1351\n",
            "         2.0       0.77      0.99      0.87        98\n",
            "         3.0       0.99      0.98      0.98      1121\n",
            "         4.0       1.00      0.77      0.87       128\n",
            "\n",
            "    accuracy                           0.98      2698\n",
            "   macro avg       0.94      0.93      0.93      2698\n",
            "weighted avg       0.98      0.98      0.98      2698\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#128 pruning\n"
      ],
      "metadata": {
        "id": "U584IZBejXX9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "student_model.save(\"/content/drive/MyDrive/DL/KD/128_5_7_cnn_student.h5\")\n",
        "pruned_keras_file = \"/content/drive/MyDrive/DL/KD/128_5_7_cnn_student_strip.h5\"\n",
        "pruned_tflite_file = \"/content/drive/MyDrive/DL/KD/128_5_7_cnn_student_strip_tflite.h5\"\n",
        "import tempfile\n",
        "\n",
        "\n",
        "import tensorflow_model_optimization as tfmot\n",
        "\n",
        "prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n",
        "\n",
        "# Compute end step to finish pruning after 2 epochs.\n",
        "batch_size = 32\n",
        "epochs = 2\n",
        "validation_split = 0.1 # 10% of training set will be used for validation set. \n",
        "\n",
        "end_step = 300*epochs\n",
        "# Define model for pruning.\n",
        "pruning_params = {\n",
        "      'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=0.50,\n",
        "                                                               final_sparsity=0.80,\n",
        "                                                               begin_step=0,\n",
        "                                                               end_step=end_step)\n",
        "}\n",
        "\n",
        "model_for_pruning = prune_low_magnitude(student_model, **pruning_params)\n",
        "\n",
        "# `prune_low_magnitude` requires a recompile.\n",
        "model_for_pruning.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "\n",
        "logdir = tempfile.mkdtemp()\n",
        "\n",
        "callbacks = [\n",
        "  tfmot.sparsity.keras.UpdatePruningStep(),\n",
        "  tfmot.sparsity.keras.PruningSummaries(log_dir=logdir),\n",
        "]\n",
        "\n",
        "model_for_pruning.fit(train_ds, epochs=epochs, callbacks=callbacks, validation_data=val_ds,\n",
        ")\n",
        "\n",
        "predictions = np.array([])\n",
        "labels =  np.array([])\n",
        "\n",
        "for x, y in test_ds:\n",
        "  predictions = np.concatenate([predictions, model_for_pruning.predict(x).argmax(axis =1)+1])\n",
        "  labels = np.concatenate([labels, y.numpy()])\n",
        "\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(labels,predictions))\n",
        "\n",
        "\n",
        "model_for_export = tfmot.sparsity.keras.strip_pruning(model_for_pruning)\n",
        "\n",
        "# _, pruned_keras_file = tempfile.mkstemp('.h5')\n",
        "tf.keras.models.save_model(model_for_export, pruned_keras_file, include_optimizer=False)\n",
        "print('Saved pruned Keras model to:', pruned_keras_file)\n",
        "\n",
        "\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model_for_export)\n",
        "pruned_tflite_model = converter.convert()\n",
        "\n",
        "# _, pruned_tflite_file = tempfile.mkstemp('.tflite')\n",
        "\n",
        "with open(pruned_tflite_file, 'wb') as f:\n",
        "  f.write(pruned_tflite_model)\n",
        "\n",
        "print('Saved pruned TFLite model to:', pruned_tflite_file)\n",
        "\n",
        "def get_gzipped_model_size(file):\n",
        "  # Returns size of gzipped model, in bytes.\n",
        "  import os\n",
        "  import zipfile\n",
        "\n",
        "  _, zipped_file = tempfile.mkstemp('.zip')\n",
        "  with zipfile.ZipFile(zipped_file, 'w', compression=zipfile.ZIP_DEFLATED) as f:\n",
        "    f.write(file)\n",
        "\n",
        "  return os.path.getsize(zipped_file)\n",
        "print(\"Size of gzipped baseline Keras model: %.2f bytes\" % (get_gzipped_model_size(keras_file)))\n",
        "print(\"Size of gzipped pruned Keras model: %.2f bytes\" % (get_gzipped_model_size(pruned_keras_file)))\n",
        "print(\"Size of gzipped pruned TFlite model: %.2f bytes\" % (get_gzipped_model_size(pruned_tflite_file)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ac821ff-48ca-4232-81d8-05fa97bdc939",
        "id": "AcSnYvcTjobt"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow_model_optimization/python/core/sparsity/keras/pruning_wrapper.py:218: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
            "  aggregation=tf.VariableAggregation.MEAN)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow_model_optimization/python/core/sparsity/keras/pruning_wrapper.py:225: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
            "  aggregation=tf.VariableAggregation.MEAN)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow_model_optimization/python/core/sparsity/keras/pruning_wrapper.py:238: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
            "  trainable=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "304/304 [==============================] - 436s 1s/step - loss: 0.1193 - accuracy: 0.9634 - val_loss: 0.7413 - val_accuracy: 0.6970\n",
            "Epoch 2/2\n",
            "304/304 [==============================] - 405s 1s/step - loss: 0.1127 - accuracy: 0.9693 - val_loss: 0.3171 - val_accuracy: 0.8945\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         1.0       1.00      0.89      0.94      1351\n",
            "         2.0       0.30      1.00      0.46        98\n",
            "         3.0       0.98      0.93      0.96      1121\n",
            "         4.0       0.72      0.62      0.66       128\n",
            "\n",
            "    accuracy                           0.90      2698\n",
            "   macro avg       0.75      0.86      0.76      2698\n",
            "weighted avg       0.95      0.90      0.92      2698\n",
            "\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Saved pruned Keras model to: /content/drive/MyDrive/DL/KD/128_5_7_cnn_student_strip.h5\n",
            "INFO:tensorflow:Assets written to: /tmp/tmptzanlkui/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved pruned TFLite model to: /content/drive/MyDrive/DL/KD/128_5_7_cnn_student_strip_tflite.h5\n",
            "Size of gzipped baseline Keras model: 636053.00 bytes\n",
            "Size of gzipped pruned Keras model: 230472.00 bytes\n",
            "Size of gzipped pruned TFlite model: 210538.00 bytes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ABPDq2nBE11b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "b-jklOl-jwBA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "distiller = Distiller(student=student_model, teacher=teacher_model)\n",
        "distiller.compile(\n",
        "    optimizer=keras.optimizers.Adam(),\n",
        "    metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
        "    student_loss_fn=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    distillation_loss_fn=keras.losses.KLDivergence(),\n",
        "    alpha=0.1,\n",
        "    temperature=5,\n",
        ")\n",
        "\n",
        "# Distill teacher to student\n",
        "distiller.fit(train_ds, epochs=7)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58cefb8e-0ec0-4919-85ae-3b41093efe53",
        "id": "SMndF5CTjwQ3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "304/304 [==============================] - 403s 1s/step - sparse_categorical_accuracy: 0.8386 - student_loss: 0.4901 - distillation_loss: 0.0013\n",
            "Epoch 2/7\n",
            "304/304 [==============================] - 345s 1s/step - sparse_categorical_accuracy: 0.9328 - student_loss: 0.2001 - distillation_loss: 5.1175e-04\n",
            "Epoch 3/7\n",
            "304/304 [==============================] - 343s 1s/step - sparse_categorical_accuracy: 0.9599 - student_loss: 0.1325 - distillation_loss: 3.3098e-04\n",
            "Epoch 4/7\n",
            "304/304 [==============================] - 345s 1s/step - sparse_categorical_accuracy: 0.9684 - student_loss: 0.1050 - distillation_loss: 2.5743e-04\n",
            "Epoch 5/7\n",
            "304/304 [==============================] - 343s 1s/step - sparse_categorical_accuracy: 0.9790 - student_loss: 0.0740 - distillation_loss: 1.7754e-04\n",
            "Epoch 6/7\n",
            "304/304 [==============================] - 355s 1s/step - sparse_categorical_accuracy: 0.9810 - student_loss: 0.0605 - distillation_loss: 1.5205e-04\n",
            "Epoch 7/7\n",
            "304/304 [==============================] - 368s 1s/step - sparse_categorical_accuracy: 0.9823 - student_loss: 0.0572 - distillation_loss: 1.4149e-04\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f330cda6d50>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#128,256 student"
      ],
      "metadata": {
        "id": "ZkQ_eq5lzymB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(labels,predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0220105f-4bfc-47b7-ee3b-27e8b255e442",
        "id": "1a5IQTerz6QO"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         1.0       1.00      0.99      0.99      1351\n",
            "         2.0       0.77      1.00      0.87        98\n",
            "         3.0       1.00      0.96      0.98      1121\n",
            "         4.0       0.82      1.00      0.90       128\n",
            "\n",
            "    accuracy                           0.98      2698\n",
            "   macro avg       0.90      0.99      0.94      2698\n",
            "weighted avg       0.98      0.98      0.98      2698\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 128,256 pruning\n"
      ],
      "metadata": {
        "id": "3MssS7sbz-ip"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "student_model.save(\"/content/drive/MyDrive/DL/KD/128_256__5_7_cnn_student.h5\")\n",
        "pruned_keras_file = \"/content/drive/MyDrive/DL/KD/128_256__5_7_cnn_student_strip.h5\"\n",
        "pruned_tflite_file = \"/content/drive/MyDrive/DL/KD/128_256__5_7_cnn_student_strip_tflite.h5\"\n",
        "import tempfile\n",
        "\n",
        "\n",
        "import tensorflow_model_optimization as tfmot\n",
        "\n",
        "prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n",
        "\n",
        "# Compute end step to finish pruning after 2 epochs.\n",
        "batch_size = 32\n",
        "epochs = 2\n",
        "validation_split = 0.1 # 10% of training set will be used for validation set. \n",
        "\n",
        "end_step = 300*epochs\n",
        "# Define model for pruning.\n",
        "pruning_params = {\n",
        "      'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=0.50,\n",
        "                                                               final_sparsity=0.80,\n",
        "                                                               begin_step=0,\n",
        "                                                               end_step=end_step)\n",
        "}\n",
        "\n",
        "model_for_pruning = prune_low_magnitude(student_model, **pruning_params)\n",
        "\n",
        "# `prune_low_magnitude` requires a recompile.\n",
        "model_for_pruning.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "\n",
        "logdir = tempfile.mkdtemp()\n",
        "\n",
        "callbacks = [\n",
        "  tfmot.sparsity.keras.UpdatePruningStep(),\n",
        "  tfmot.sparsity.keras.PruningSummaries(log_dir=logdir),\n",
        "]\n",
        "\n",
        "model_for_pruning.fit(train_ds, epochs=epochs, callbacks=callbacks, validation_data=val_ds,\n",
        ")\n",
        "\n",
        "predictions = np.array([])\n",
        "labels =  np.array([])\n",
        "\n",
        "for x, y in test_ds:\n",
        "  predictions = np.concatenate([predictions, model_for_pruning.predict(x).argmax(axis =1)+1])\n",
        "  labels = np.concatenate([labels, y.numpy()])\n",
        "\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(labels,predictions))\n",
        "\n",
        "\n",
        "model_for_export = tfmot.sparsity.keras.strip_pruning(model_for_pruning)\n",
        "\n",
        "# _, pruned_keras_file = tempfile.mkstemp('.h5')\n",
        "tf.keras.models.save_model(model_for_export, pruned_keras_file, include_optimizer=False)\n",
        "print('Saved pruned Keras model to:', pruned_keras_file)\n",
        "\n",
        "\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model_for_export)\n",
        "pruned_tflite_model = converter.convert()\n",
        "\n",
        "# _, pruned_tflite_file = tempfile.mkstemp('.tflite')\n",
        "\n",
        "with open(pruned_tflite_file, 'wb') as f:\n",
        "  f.write(pruned_tflite_model)\n",
        "\n",
        "print('Saved pruned TFLite model to:', pruned_tflite_file)\n",
        "\n",
        "def get_gzipped_model_size(file):\n",
        "  # Returns size of gzipped model, in bytes.\n",
        "  import os\n",
        "  import zipfile\n",
        "\n",
        "  _, zipped_file = tempfile.mkstemp('.zip')\n",
        "  with zipfile.ZipFile(zipped_file, 'w', compression=zipfile.ZIP_DEFLATED) as f:\n",
        "    f.write(file)\n",
        "\n",
        "  return os.path.getsize(zipped_file)\n",
        "print(\"Size of gzipped baseline Keras model: %.2f bytes\" % (get_gzipped_model_size(keras_file)))\n",
        "print(\"Size of gzipped pruned Keras model: %.2f bytes\" % (get_gzipped_model_size(pruned_keras_file)))\n",
        "print(\"Size of gzipped pruned TFlite model: %.2f bytes\" % (get_gzipped_model_size(pruned_tflite_file)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9088ce05-91c1-4b40-f99f-86ff916d6c42",
        "id": "iLfEgea70BkB"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow_model_optimization/python/core/sparsity/keras/pruning_wrapper.py:218: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
            "  aggregation=tf.VariableAggregation.MEAN)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow_model_optimization/python/core/sparsity/keras/pruning_wrapper.py:225: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
            "  aggregation=tf.VariableAggregation.MEAN)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow_model_optimization/python/core/sparsity/keras/pruning_wrapper.py:238: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
            "  trainable=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "304/304 [==============================] - 422s 1s/step - loss: 0.0288 - accuracy: 0.9915 - val_loss: 1.0486 - val_accuracy: 0.3080\n",
            "Epoch 2/2\n",
            "304/304 [==============================] - 409s 1s/step - loss: 0.0195 - accuracy: 0.9948 - val_loss: 0.0278 - val_accuracy: 0.9948\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         1.0       1.00      1.00      1.00      1351\n",
            "         2.0       0.96      1.00      0.98        98\n",
            "         3.0       1.00      0.99      1.00      1121\n",
            "         4.0       0.99      0.98      0.99       128\n",
            "\n",
            "    accuracy                           1.00      2698\n",
            "   macro avg       0.99      0.99      0.99      2698\n",
            "weighted avg       1.00      1.00      1.00      2698\n",
            "\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Saved pruned Keras model to: /content/drive/MyDrive/DL/KD/128_256__5_7_cnn_student_strip.h5\n",
            "INFO:tensorflow:Assets written to: /tmp/tmphsgcr4h_/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved pruned TFLite model to: /content/drive/MyDrive/DL/KD/128_256__5_7_cnn_student_strip_tflite.h5\n",
            "Size of gzipped baseline Keras model: 1633862.00 bytes\n",
            "Size of gzipped pruned Keras model: 568672.00 bytes\n",
            "Size of gzipped pruned TFlite model: 541135.00 bytes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "xCNe1WeG0U2I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "distiller = Distiller(student=student_model, teacher=teacher_model)\n",
        "distiller.compile(\n",
        "    optimizer=keras.optimizers.Adam(),\n",
        "    metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
        "    student_loss_fn=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    distillation_loss_fn=keras.losses.KLDivergence(),\n",
        "    alpha=0.1,\n",
        "    temperature=5,\n",
        ")\n",
        "\n",
        "# Distill teacher to student\n",
        "distiller.fit(train_ds, epochs=7)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0460abc-b7bb-4287-a34e-134d6ee01ee8",
        "id": "k3a9jvIV0VGh"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "304/304 [==============================] - 421s 1s/step - sparse_categorical_accuracy: 0.9248 - student_loss: 0.2306 - distillation_loss: 5.9901e-04\n",
            "Epoch 2/7\n",
            "304/304 [==============================] - 388s 1s/step - sparse_categorical_accuracy: 0.9854 - student_loss: 0.0476 - distillation_loss: 1.1697e-04\n",
            "Epoch 3/7\n",
            "304/304 [==============================] - 386s 1s/step - sparse_categorical_accuracy: 0.9920 - student_loss: 0.0287 - distillation_loss: 6.8075e-05\n",
            "Epoch 4/7\n",
            "304/304 [==============================] - 383s 1s/step - sparse_categorical_accuracy: 0.9936 - student_loss: 0.0237 - distillation_loss: 5.7463e-05\n",
            "Epoch 5/7\n",
            "304/304 [==============================] - 385s 1s/step - sparse_categorical_accuracy: 0.9947 - student_loss: 0.0201 - distillation_loss: 4.4786e-05\n",
            "Epoch 6/7\n",
            "304/304 [==============================] - 387s 1s/step - sparse_categorical_accuracy: 0.9955 - student_loss: 0.0149 - distillation_loss: 3.5918e-05\n",
            "Epoch 7/7\n",
            "304/304 [==============================] - 386s 1s/step - sparse_categorical_accuracy: 0.9966 - student_loss: 0.0102 - distillation_loss: 2.4775e-05\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7feadc16b0d0>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#####################scratch##########################################"
      ],
      "metadata": {
        "id": "aFkDsCiaE3Ur"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#128 \n"
      ],
      "metadata": {
        "id": "9IlbDKrNE5kc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "predictions = np.array([])\n",
        "labels =  np.array([])\n",
        "for x, y in test_ds:\n",
        "  temp = model.predict(x)\n",
        "  predictions = np.concatenate([predictions, model.predict(x).argmax(axis =1)+1])\n",
        "  labels = np.concatenate([labels, y.numpy()])\n",
        "\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(labels,predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OqBPf_yn3JH2",
        "outputId": "24399758-84e7-4193-815e-622a21e4e514"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         1.0       0.89      1.00      0.94      1351\n",
            "         2.0       0.92      0.70      0.80        98\n",
            "         3.0       0.96      0.94      0.95      1121\n",
            "         4.0       1.00      0.07      0.13       128\n",
            "\n",
            "    accuracy                           0.92      2698\n",
            "   macro avg       0.94      0.68      0.70      2698\n",
            "weighted avg       0.92      0.92      0.90      2698\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##128,256"
      ],
      "metadata": {
        "id": "IJD19lCCFSWr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "LYPsUTian37p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "predictions = np.array([])\n",
        "labels =  np.array([])\n",
        "for x, y in test_ds:\n",
        "  temp = model.predict(x)\n",
        "  predictions = np.concatenate([predictions, model.predict(x).argmax(axis =1)+1])\n",
        "  labels = np.concatenate([labels, y.numpy()])\n",
        "\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(labels,predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "faa54267-69f0-4944-fb61-1c116a0e1966",
        "id": "cM69SHhJn4QB"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         1.0       0.99      0.87      0.93      1351\n",
            "         2.0       0.94      0.73      0.82        98\n",
            "         3.0       0.79      0.99      0.88      1121\n",
            "         4.0       0.96      0.17      0.29       128\n",
            "\n",
            "    accuracy                           0.88      2698\n",
            "   macro avg       0.92      0.69      0.73      2698\n",
            "weighted avg       0.90      0.88      0.87      2698\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#prune\n"
      ],
      "metadata": {
        "id": "zmKP_0dGn5Yl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "dK-KocIsn-oG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = np.array([])\n",
        "labels =  np.array([])\n",
        "\n",
        "for x, y in test_ds:\n",
        "  predictions = np.concatenate([predictions, model_for_pruning.predict(x).argmax(axis =1)+1])\n",
        "  labels = np.concatenate([labels, y.numpy()])\n",
        "\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(labels,predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zknuwd8nf4in",
        "outputId": "00221fc7-9bca-42f5-b4c7-7a1a10b83434"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         1.0       0.85      1.00      0.92      1351\n",
            "         2.0       0.97      0.76      0.85        98\n",
            "         3.0       0.98      0.90      0.94      1121\n",
            "         4.0       0.00      0.00      0.00       128\n",
            "\n",
            "    accuracy                           0.90      2698\n",
            "   macro avg       0.70      0.66      0.68      2698\n",
            "weighted avg       0.87      0.90      0.88      2698\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "uxCHAIB0n-xs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}